import streamlit as st
import pandas as pd
import sys
import os
from sqlalchemy.orm import Session
from datetime import datetime, timedelta

# Add project root to path to allow imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.database import get_db, Article, SessionLocal, delete_article, add_source, delete_source, get_sources, get_all_articles, get_setting, set_setting
from src.crawler import Crawler
from src.processor import Processor

st.set_page_config(page_title="Info Stream", layout="wide")

def get_data():
    db: Session = SessionLocal()
    # Fetch high value articles
    articles = db.query(Article).filter(Article.is_high_value == True).order_by(Article.fetched_at.desc()).all()
    db.close()
    return articles

def run_fetch_cycle():
    """Runs the crawler and processor."""
    sources = get_sources()
    urls = [s.url for s in sources]
    
    if not urls:
        st.warning("No sources configured! Add some URLs in the sidebar.")
        return

    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # 1. Crawl
    status_text.text("ğŸ•·ï¸ Crawling sources...")
    crawler = Crawler()
    total_urls = len(urls)
    for i, url in enumerate(urls):
        crawler.crawl_site(url)
        progress_bar.progress((i + 1) / (total_urls * 2))
    crawler.close()
    
    # 2. Process
    status_text.text("ğŸ§  Analyzing content...")
    processor = Processor()
    processor.process_pending_articles()
    processor.close()
    progress_bar.progress(100)
    
    status_text.text("âœ… Done!")
    st.rerun()

def main():
    st.title("ğŸŒŠ Information Stream & Analysis")

    # --- Sidebar: Configuration & Sources ---
    st.sidebar.header("Configuration")
    
    st.sidebar.subheader("Data Sources")
    sources = get_sources()
    for s in sources:
        col1, col2 = st.sidebar.columns([0.8, 0.2])
        col1.text(s.url)
        if col2.button("ğŸ—‘ï¸", key=f"del_src_{s.id}"):
            delete_source(s.id)
            st.rerun()
            
    new_url = st.sidebar.text_input("Add URL", placeholder="https://example.com")
    if st.sidebar.button("Add Source"):
        if new_url:
            if add_source(new_url):
                st.sidebar.success("Added!")
                st.rerun()
            else:
                st.sidebar.error("Failed (Duplicate?)")

    st.sidebar.markdown("---")
    if st.sidebar.button("ğŸš€ Fetch New Data", type="primary"):
        run_fetch_cycle()

    if st.sidebar.button("Refresh View"):
        st.rerun()

    # --- Main Content ---
    tab1, tab2, tab3 = st.tabs(["Information Stream", "Daily Report", "Developer Dashboard"])

    with tab1:
        st.header("Latest High-Value Updates")
        articles = get_data()
        
        if not articles:
            st.info("No high-value articles found yet. Add sources and click 'Fetch New Data'!")
        
        # Group by date
        grouped_articles = {}
        for article in articles:
            date_key = article.fetched_at.date()
            if date_key not in grouped_articles:
                grouped_articles[date_key] = []
            grouped_articles[date_key].append(article)
            
        # Display grouped articles
        for date_key in sorted(grouped_articles.keys(), reverse=True):
            # Date Header
            if date_key == datetime.utcnow().date():
                date_label = "Today"
            elif date_key == (datetime.utcnow() - timedelta(days=1)).date():
                date_label = "Yesterday"
            else:
                date_label = date_key.strftime("%Y-%m-%d")
                
            st.subheader(f"ğŸ“… {date_label}")
            
            for article in grouped_articles[date_key]:
                col1, col2 = st.columns([0.9, 0.1])
                with col1:
                    with st.expander(f"{article.title}"):
                        st.markdown(f"**Source**: [{article.url}]({article.url})")
                        st.markdown("### Analysis Report")
                        st.markdown(article.analysis_report or "Analysis pending...")
                        st.divider()
                        st.markdown("### Original Content Snippet")
                        st.text(article.content[:500] + "..." if article.content else "No content")
                with col2:
                    if st.button("ğŸ—‘ï¸", key=f"del_{article.id}", help="Delete this article"):
                        if delete_article(article.id):
                            st.success("Deleted!")
                            st.rerun()
                        else:
                            st.error("Failed to delete.")

    with tab2:
        st.header("Daily Summary")
        # Filter for last 24 hours
        yesterday = datetime.utcnow() - timedelta(days=1)
        recent_articles = [a for a in articles if a.fetched_at >= yesterday]
        
        if not recent_articles:
            st.write("No articles in the last 24 hours.")
        else:
            st.write(f"**Total Articles**: {len(recent_articles)}")
            st.markdown("---")
            for article in recent_articles:
                st.subheader(article.title)
                st.markdown(article.analysis_report or "No analysis available.")
                st.markdown("---")

    with tab3:
        st.header("ğŸ› ï¸ Developer Dashboard")
        
        # --- Prompt Editor ---
        with st.expander("ğŸ“ Prompt Configuration", expanded=False):
            st.info("ğŸ’¡ **æç¤º**ï¼šè¯·ä¸“æ³¨äºä¿®æ”¹ç­›é€‰æ ‡å‡†ã€è§’è‰²è®¾å®šå’Œåˆ†æç»´åº¦ã€‚**ä¸éœ€è¦**åœ¨ Prompt ä¸­æŒ‡å®šè¾“å‡ºæ ¼å¼ï¼ˆå¦‚ JSONï¼‰ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ¥ç®¡æ ¼å¼æ§åˆ¶ã€‚")
            st.info("Edit the prompts used by the AI. Use `{articles_list}` in Selection and `{content}` in Analysis as placeholders.")
            
            # Default Prompts (Same as in processor.py, for initial display if DB is empty)
            default_selection = """Role: å®è§‚çº¢åˆ©ç‹™å‡»æ‰‹
Context: åªæœ‰èƒ½æ”¹å˜ç¤¾ä¼šèµ„æºåˆ†é…è§„åˆ™çš„æ–°é—»æ‰å€¼å¾—å…³æ³¨
Criteria: 
1. æ˜¯å¦æ¶‰åŠ[ç¨æ”¶/ç¤¾ä¿/æˆ·ç±]ç­‰é¡¶å±‚è®¾è®¡å˜åŠ¨ï¼Ÿ(æ”¿ç­–çº¢åˆ©/é»‘å¤©é¹…) 
2. æ˜¯å¦å‡ºç°è·¨é˜¶å±‚çš„[é€ å¯Œ/è¿”è´«]ç°è±¡ï¼Ÿ(é£å£é¢„è­¦) 
3. æ˜¯å¦æ”¹å˜äº†[ç‰¹å®šè¡Œä¸š]çš„å‡†å…¥é—¨æ§›ï¼Ÿ(ç«äº‰å£å’) 

Task:
Review the following articles. Select the TOP 5 most impactful articles based on the criteria.
Rank them from 1 (most impactful) to 5.

Articles:
{articles_list}
"""
            default_analysis = """Role: å†·é…·çš„æ”¿ç­–å¥—åˆ©åˆ†æå¸ˆ
Task: Analyze the text.

Content:
{content} 

Requirements:
1. ã€çŸ›ç›¾ç‚¹ã€‘(contradictions): æå–æ–‡ä¸­â€œæ—¢è¦...åˆè¦...â€çš„å†…å®¹ï¼Œå¹¶åˆ¤æ–­å“ªä¸€ä¸ªæ˜¯å½“å‰çš„çœŸå®KPIï¼ˆæ’åœ¨åé¢æˆ–æœ‰é‡åŒ–æŒ‡æ ‡çš„ï¼‰ã€‚
2. ã€æ¸©å·®ã€‘(temperature_diff): å¯¹æ¯”è¯¥è¡Œä¸šå»å¹´çš„å¸¸è§„è¡¨è¿°ï¼Œæå–å˜åŒ–çš„å½¢å®¹è¯ï¼ˆå¦‚ä»â€œå¤§åŠ›å‘å±•â€å˜ä¸ºâ€œè§„èŒƒæœ‰åºâ€ï¼‰ã€‚
3. ã€è´Ÿé¢æ¸…å•ã€‘(negative_list): æå–æ‰€æœ‰â€œä¸¥ç¦â€ã€â€œä¸å¾—â€ã€â€œæ¸…ç†â€åé¢çš„å…·ä½“è¡Œä¸ºã€‚
4. ã€å®ä½“ä¿¡æ¯ã€‘(entities): æå–æ–‡ä¸­æ‰€æœ‰çš„é‡‘é¢ã€æ—¥æœŸã€è´Ÿè´£éƒ¨é—¨ã€‚
5. ã€ä¸€å¥è¯ç»“è®ºã€‘(conclusion): è¿™æ–‡ä»¶æ˜¯å‘é’±çš„ï¼ˆçº¢åˆ©ï¼‰ï¼Œè¿˜æ˜¯æ”¶ç½‘çš„ï¼ˆæ•´é¡¿ï¼‰ï¼Ÿ
"""

            current_selection = get_setting("prompt_selection", default_selection)
            current_analysis = get_setting("prompt_analysis", default_analysis)
            
            new_selection = st.text_area("Selection Prompt (Stage 2)", value=current_selection, height=300)
            new_analysis = st.text_area("Analysis Prompt (Stage 3)", value=current_analysis, height=300)
            
            if st.button("Save Prompts"):
                set_setting("prompt_selection", new_selection)
                set_setting("prompt_analysis", new_analysis)
                st.success("Prompts updated!")

        st.divider()
        
        st.subheader("Database View")
        all_articles = get_all_articles()
        
        # Metrics
        total = len(all_articles)
        processed = sum(1 for a in all_articles if a.is_processed)
        high_value = sum(1 for a in all_articles if a.is_high_value)
        
        m1, m2, m3 = st.columns(3)
        m1.metric("Total Articles", total)
        m2.metric("Processed", processed)
        m3.metric("High Value", high_value)
        
        st.divider()
        
        # Data Table
        if all_articles:
            data = [{
                "ID": a.id,
                "Title": a.title,
                "URL": a.url,
                "Fetched": a.fetched_at,
                "Processed": a.is_processed,
                "High Value": a.is_high_value
            } for a in all_articles]
            st.dataframe(pd.DataFrame(data), use_container_width=True)
        
        st.divider()
        
        # Delete Action
        st.subheader("Danger Zone")
        del_id = st.number_input("Enter Article ID to Delete", min_value=1, step=1)
        if st.button("Delete Article by ID", type="primary"):
            if delete_article(del_id):
                st.success(f"Deleted Article {del_id}")
                st.rerun()
            else:
                st.error(f"Article {del_id} not found.")

if __name__ == "__main__":
    main()
