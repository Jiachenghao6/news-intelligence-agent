
# ğŸ¦… Macro Policy Arbitrage Intelligence System | å®è§‚æ”¿ç­–å¥—åˆ©æƒ…æŠ¥ç³»ç»Ÿ

-----

## ğŸ‡ºğŸ‡¸ English Version

### ğŸ“– Introduction

This is an automated intelligence analysis system based on **LLM Agent** architecture. It automatically scrapes internet news and utilizes AI for a two-stage "Selection-Analysis" process. It precisely captures macro signals regarding top-level design changes, wealth transfer between social classes, and industry entry barrier shifts from massive amounts of information, generating structured analysis reports.

### âœ¨ Core Features

1.  **ğŸ•·ï¸ Auto-Crawler (Data Ingestion)**

      * **Custom Sources**: Supports adding custom news source URLs via the dashboard.
      * **Smart Deduplication**: Intelligent filtering to prevent redundant scraping of existing URLs.
      * **Universal Parsing**: Heuristic-based universal web page parsing adaptable to various news sites.

2.  **ğŸ§  Dual-Stage AI Pipeline (The Brain)**

      * **Stage 1: The Macro Bonus Sniper**
          * Uses the lightweight `Flash-Lite` model to rapidly scan batches of article titles.
          * Filters the **Top 5** most valuable signals based on three hard criteria: "Tax/Social Security Changes", "Wealth Creation/Poverty Return", and "Industry Entry Barriers".
      * **Stage 2: The Policy Arbitrage Analyst**
          * Uses the high-performance `Flash` model for deep reading of selected high-value articles.
          * **Structured Output**: Automatically extracts "Contradictions", "Policy Temperature Gaps", "Negative Lists", "Entity Info", and provides a "One-sentence Conclusion".

3.  **ğŸ“Š Intelligence Dashboard (UI)**

      * **Interactive Frontend**: Built with **Streamlit** for a smooth user experience.
      * **Timeline View**: View intelligence streams chronologically or by daily summary.
      * **Developer Dashboard**: Supports real-time online adjustment of LLM Prompts (System Instructions) without restarting the service.

4.  **ğŸ›¡ï¸ Enterprise-Grade Stability**

      * **JSON Schema Enforcement**: Uses Google Gemini's structured output feature to ensure 100% stable JSON formats, eliminating parsing errors.
      * **Resilience**: Features resume-from-break capability and automatic backlog clearing mechanisms (Batch Processing Loop).

### ğŸ› ï¸ Tech Stack

  * **Language**: Python 3.10+
  * **LLM API**: Google Gemini (Supports `gemini-2.5-flash` series)
  * **Web Framework**: Streamlit
  * **Database**: SQLite (SQLAlchemy ORM)
  * **Scheduler**: APScheduler
  * **Crawler**: Requests + BeautifulSoup4

### ğŸš€ Quick Start

#### 1\. Clone Repository

```bash
git clone <your-repo-url>
cd news-intelligence-agent
```

#### 2\. Install Dependencies

It is recommended to use a virtual environment:

```bash
python -m venv venv
source venv/bin/activate  # Mac/Linux
# venv\Scripts\activate   # Windows

pip install -r requirements.txt
```

#### 3\. Configure Environment

Create a `.env` file in the root directory and add your API Key:

```ini
# .env file content
GEMINI_API_KEY=your_google_api_key_here

# Optional Config
LLM_PROVIDER=gemini
HIGH_VALUE_KEYWORDS=AI,Policy,Economy,Reform
```

#### 4\. Run System

**Option A: Launch Visual Dashboard (Recommended)**
This creates a web interface to manage sources and view reports.

```bash
streamlit run news/src/app.py
```

  * Open your browser at `http://localhost:8501`.
  * Add news URLs in the sidebar.
  * Click **"ğŸš€ Fetch New Data"** to start the agent.

**Option B: Headless Background Task**
Run the crawler and processor in a loop (e.g., every hour).

```bash
python news/main.py --loop
```

-----

## ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç‰ˆ

### ğŸ“– é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªåŸºäº **LLM Agent** æ¶æ„çš„è‡ªåŠ¨åŒ–æƒ…æŠ¥åˆ†æç³»ç»Ÿã€‚å®ƒèƒ½å¤Ÿè‡ªåŠ¨æŠ“å–äº’è”ç½‘æ–°é—»ï¼Œåˆ©ç”¨ AI è¿›è¡Œä¸¤é˜¶æ®µçš„â€œç­›é€‰-åˆ†æâ€å¤„ç†ï¼Œä»æµ·é‡ä¿¡æ¯ä¸­ç²¾å‡†æ•æ‰æ¶‰åŠé¡¶å±‚è®¾è®¡å˜åŠ¨ã€é˜¶å±‚è´¢å¯Œè½¬ç§»å’Œè¡Œä¸šå‡†å…¥é—¨æ§›å˜åŒ–çš„å®è§‚ä¿¡å·ï¼Œå¹¶ç”Ÿæˆç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Šã€‚

### âœ¨ æ ¸å¿ƒåŠŸèƒ½

1.  **ğŸ•·ï¸ è‡ªåŠ¨æ•°æ®é‡‡é›† (æ•°æ®æ‘„å…¥)**

      * **è‡ªå®šä¹‰æº**: æ”¯æŒåœ¨ä»ªè¡¨ç›˜ä¸­æ·»åŠ ä»»æ„æ–°é—»æº URLã€‚
      * **æ™ºèƒ½å»é‡**: é˜²æ­¢é‡å¤æŠ“å–å·²å­˜åœ¨çš„é“¾æ¥ã€‚
      * **é€šç”¨è§£æ**: åŸºäºå¯å‘å¼è§„åˆ™çš„ç½‘é¡µè§£æç®—æ³•ï¼Œé€‚åº”æ€§å¼ºã€‚

2.  **ğŸ§  åŒé˜¶æ®µ AI å¤„ç†æµæ°´çº¿ (æ™ºèƒ½æ ¸å¿ƒ)**

      * **ç¬¬ä¸€é˜¶æ®µï¼šå®è§‚çº¢åˆ©ç‹™å‡»æ‰‹ (The Sniper)**
          * ä½¿ç”¨è½»é‡çº§æ¨¡å‹ (`Flash-Lite`) å¿«é€Ÿæ‰«ææ‰¹é‡æ–‡ç« æ ‡é¢˜ã€‚
          * æ ¹æ®â€œç¨æ”¶/ç¤¾ä¿å˜åŠ¨â€ã€â€œé€ å¯Œ/è¿”è´«ç°è±¡â€ã€â€œè¡Œä¸šå‡†å…¥å£å’â€ä¸‰å¤§ç¡¬æŒ‡æ ‡ï¼Œä»æµ·é‡èµ„è®¯ä¸­ç­›é€‰å‡º **Top 5** æœ€å…·ä»·å€¼çš„ä¿¡å·ã€‚
      * **ç¬¬äºŒé˜¶æ®µï¼šæ”¿ç­–å¥—åˆ©åˆ†æå¸ˆ (The Analyst)**
          * ä½¿ç”¨é«˜æ€§èƒ½æ¨¡å‹ (`Flash`) å¯¹ç­›é€‰å‡ºçš„æ–‡ç« è¿›è¡Œæ·±åº¦ç ”è¯»ã€‚
          * **ç»“æ„åŒ–è¾“å‡º**: è‡ªåŠ¨æå–â€œçŸ›ç›¾ç‚¹â€ã€â€œæ”¿ç­–æ¸©å·®â€ã€â€œè´Ÿé¢æ¸…å•â€ã€â€œå®ä½“ä¿¡æ¯â€åŠâ€œä¸€å¥è¯ç»“è®ºâ€ã€‚

3.  **ğŸ“Š å¯è§†åŒ–æƒ…æŠ¥çœ‹æ¿ (å‰ç«¯)**

      * **äº¤äº’å¼ UI**: åŸºäº **Streamlit** æ„å»ºã€‚
      * **æ—¶é—´è½´è§†å›¾**: æ”¯æŒæŒ‰æ—¶é—´é¡ºåºæˆ–æ—¥æŠ¥å½¢å¼æŸ¥çœ‹æƒ…æŠ¥æµã€‚
      * **å¼€å‘è€…åå°**: æ”¯æŒåœ¨çº¿å®æ—¶è°ƒæ•´ LLM çš„ Promptï¼ˆæç¤ºè¯ï¼‰ï¼Œæ— éœ€é‡å¯æœåŠ¡å³å¯ä¼˜åŒ– AI äººè®¾ã€‚

4.  **ğŸ›¡ï¸ ä¼ä¸šçº§ç¨³å®šæ€§**

      * **JSON Schema å¼ºçº¦æŸ**: ä½¿ç”¨ Gemini åŸç”Ÿç»“æ„åŒ–è¾“å‡ºåŠŸèƒ½ï¼Œç¡®ä¿ LLM è¾“å‡ºæ ¼å¼ 100% ç¨³å®šï¼Œå½»åº•æœç»è§£ææŠ¥é”™ã€‚
      * **é«˜å¯ç”¨é€»è¾‘**: å…·å¤‡æ–­ç‚¹ç»­ä¼ èƒ½åŠ›å’Œç§¯å‹ä»»åŠ¡è‡ªåŠ¨æ¸…ç©ºæœºåˆ¶ (Batch Processing Loop)ã€‚

### ğŸ› ï¸ æŠ€æœ¯æ ˆ

  * **è¯­è¨€**: Python 3.10+
  * **å¤§æ¨¡å‹ API**: Google Gemini (æ”¯æŒ `gemini-2.5-flash` ç³»åˆ—)
  * **Web æ¡†æ¶**: Streamlit
  * **æ•°æ®åº“**: SQLite (SQLAlchemy ORM)
  * **è°ƒåº¦å™¨**: APScheduler
  * **çˆ¬è™«**: Requests + BeautifulSoup4

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### 1\. å…‹éš†é¡¹ç›®

```bash
git clone <your-repo-url>
cd news-intelligence-agent
```

#### 2\. å®‰è£…ä¾èµ–

å»ºè®®ä½¿ç”¨ Python è™šæ‹Ÿç¯å¢ƒï¼š

```bash
python -m venv venv
source venv/bin/activate  # Mac/Linux
# venv\Scripts\activate   # Windows

pip install -r requirements.txt
```

#### 3\. é…ç½®ç¯å¢ƒå˜é‡

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»ºä¸€ä¸ª `.env` æ–‡ä»¶ï¼Œå¹¶å¡«å…¥ä½ çš„ API Keyï¼š

```ini
# .env æ–‡ä»¶å†…å®¹
GEMINI_API_KEY=ä½ çš„_Google_API_Key

# å¯é€‰é…ç½®
LLM_PROVIDER=gemini
HIGH_VALUE_KEYWORDS=AI,Policy,Economy,Reform
```

#### 4\. è¿è¡Œç³»ç»Ÿ

**æ–¹å¼ Aï¼šå¯åŠ¨å¯è§†åŒ–çœ‹æ¿ (æ¨è)**
è¿™æ˜¯æœ€ç›´è§‚çš„ä½¿ç”¨æ–¹å¼ï¼Œé›†æˆäº†æ‰‹åŠ¨è§¦å‘æŠ“å–å’Œæ•°æ®æŸ¥çœ‹åŠŸèƒ½ã€‚

```bash
streamlit run news/src/app.py
```

  * æ‰“å¼€æµè§ˆå™¨è®¿é—® `http://localhost:8501`ã€‚
  * åœ¨ä¾§è¾¹æ æ·»åŠ æ–°é—»æº URLã€‚
  * ç‚¹å‡» **"ğŸš€ Fetch New Data"** å¼€å§‹è¿è¡Œ Agentã€‚

**æ–¹å¼ Bï¼šåå°é™é»˜è¿è¡Œ (å®šæ—¶ä»»åŠ¡)**
å¦‚æœä½ å¸Œæœ›è®©å®ƒåœ¨æœåŠ¡å™¨åå°æ¯å°æ—¶è‡ªåŠ¨è·‘ä¸€æ¬¡ï¼š

```bash
python news/main.py --loop
```

-----

## âš™ï¸ Configuration & Notes (é…ç½®ä¸æ³¨æ„äº‹é¡¹)

### Developer Dashboard (å¼€å‘è€…åå°)

In the Streamlit interface, navigate to the **"Developer Dashboard"** tab to:

  * **Real-time Prompt Tuning**: Dynamically modify the selection criteria and analysis dimensions.
  * **Data Management**: Delete specific articles by ID.
  * **Metrics**: View system processing statistics.

### Important Notes (æ³¨æ„äº‹é¡¹)

1.  **API Costs**: The system consumes Tokens. While Flash-Lite is used for initial screening to save costs, please monitor API usage during heavy scraping. (ç³»ç»Ÿä¼šæ¶ˆè€— Tokenã€‚è™½ç„¶ä½¿ç”¨äº† Flash-Lite è¿›è¡Œåˆç­›ä»¥èŠ‚çœæˆæœ¬ï¼Œä½†åœ¨å¤§é‡æŠ“å–æ—¶è¯·ç•™æ„ API ç”¨é‡ã€‚)
2.  **Network**: Ensure your runtime environment can connect to Google Gemini API services. (è¯·ç¡®ä¿ä½ çš„è¿è¡Œç¯å¢ƒå¯ä»¥è¿æ¥åˆ° Google æœåŠ¡ã€‚)
3.  **Crawler Etiquette**: Do not scrape target websites at excessively high frequencies to avoid triggering anti-bot mechanisms. (è¯·å‹¿å¯¹ç›®æ ‡ç½‘ç«™è¿›è¡Œè¿‡é«˜é¢‘ç‡çš„æŠ“å–ï¼Œä»¥å…è§¦å‘åçˆ¬æœºåˆ¶ã€‚)

-----

**License**: MIT
